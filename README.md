# JSON/XML to YAML Token Optimizer

**Optimize your data streams for GPT-4/4.1/5.0 and reduce LLM costs by up to 48%**

A research-backed tool demonstrating data format optimizations for Large Language Models. Built to help engineers understand token efficiency and make informed decisions about data serialization in AI applications.

## üéØ Purpose

This tool demonstrates **four progressive optimization levels** for data sent to Language Models, with accurate GPT-4/4.1/5.0 token counting using OpenAI's tiktoken library.

## üìä Optimization Levels

### Level 1: Remove Nulls/Empty (JSON)
- **Format:** Keeps JSON
- **Optimization:** Removes null values, empty strings, empty arrays/objects
- **Use Case:** Synthesis layers, backend processing
- **Pros:** Works with existing JSON parsers, no API changes needed
- **Cons:** Minimal token savings (typically <1%)
- **Safety:** ‚úÖ API Safe

### Level 2: Convert to YAML
- **Format:** YAML with minimal spacing
- **Optimization:** Better BPE (Byte Pair Encoding) tokenization
- **Use Case:** Direct LLM input, production GPT-4/5 applications
- **Pros:** 25-48% token reduction, preserves semantic meaning, optimal for LLMs
- **Cons:** Requires YAML parser (js-yaml, PyYAML)
- **Safety:** ‚úÖ LLM Safe - Recommended for production

### Level 3: Chain-of-Thought (Comments)
- **Format:** YAML with # comments
- **Optimization:** Enables LLM reasoning while keeping output parseable
- **Use Case:** Complex reasoning tasks, mathematical problems, multi-step workflows
- **Pros:** Improves accuracy on complex tasks, parseable output
- **Cons:** Adds token overhead for comments (but improves quality)
- **Safety:** ‚úÖ LLM Recommended for accuracy-critical tasks

### Level 4: Short Keys (Aggressive)
- **Format:** YAML with shortened keys
- **Optimization:** Aggressive key compression (e.g., `LicenseValidator` ‚Üí `lv`)
- **Use Case:** Storage, transmission, non-LLM processing
- **Pros:** Maximum token reduction (up to 60%)
- **Cons:** ‚ö†Ô∏è **Loses semantic context** - LLM may not understand shortened keys
- **Safety:** ‚ö†Ô∏è Use for storage/transmission only. Provide key mapping if sending to LLM.

## üî¨ Research Foundation

Based on empirical research:
- **48% token reduction** (YAML vs JSON)
- **25% character reduction**
- Better BPE token distribution for LLMs
- At scale: $11,400/month savings on 1M requests (GPT-4)

### Citations
- [Wei et al., 2022 - "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"](https://arxiv.org/abs/2201.11903)
- [Elya Livshitz - "YAML vs. JSON: Which Is More Efficient for Language Models?"](https://medium.com/@elyalivshitz/yaml-vs-json-which-is-more-efficient-for-language-models-5bdc45b6a70d)

## ‚úÖ Pros

### General Benefits
- **Accurate token counting** using OpenAI's tiktoken (GPT-4 encoding)
- **Side-by-side comparison** - see original vs optimized instantly
- **Visual Key Mapping tab** - understand key transformations
- **Research-backed** - not guesswork, based on published studies
- **Clear guidance** - each level explains when to use it

### For Engineers
- **Quick wins** - demonstrate optimizations to stakeholders
- **Educational** - understand BPE tokenization impact
- **Production-ready** - Level 2 (YAML) is safe for immediate use
- **Risk awareness** - clear warnings about semantic loss

### Cost Savings
- **YAML (Level 2)**: 8-10% reduction on typical backend JSON
- **Short Keys (Level 4)**: Up to 60% reduction (storage/transmission only)
- **At Microsoft scale**: Millions in annual savings possible

## ‚ö†Ô∏è Cons & Limitations

### Level 1 (Remove Nulls)
- **Minimal savings** - Often <1% reduction
- **Not for strict APIs** - Some APIs require null fields for schema validation
- **Data loss** - Removes information (nulls can be meaningful)

### Level 2 (YAML)
- **Parser required** - Need js-yaml or PyYAML
- **Less familiar** - Team may be more comfortable with JSON
- **Debugging** - Some tools don't support YAML as well as JSON

### Level 3 (Comments)
- **Token overhead** - Comments add tokens, but improve accuracy
- **Trade-off** - Pay more tokens for better reasoning
- **Not always needed** - Overkill for simple queries

### Level 4 (Short Keys)
- ‚ö†Ô∏è **CRITICAL: Semantic loss** - LLM loses context from key names
- **Requires mapping** - Must provide key dictionary to LLM
- **Debugging nightmare** - `lv` vs `LicenseValidator` is hard to read
- **Only for storage** - Don't send to LLM without decoding

### General Limitations
- **Your data matters** - Savings vary based on structure
- **Nulls/whitespace heavy data** shows best results
- **Already compact data** (like your Reza example) shows minimal gains
- **GPT-specific** - Tokens counts are for GPT-4/4.1/5.0 (Claude uses different tokenizer)

## üöÄ Quick Start

### Prerequisites
- Node.js 18+
- npm

### Installation
```bash
npm install
```

### Run locally
```bash
node server.js
```

Open `http://localhost:3000` in your browser.

### Test with sample data
Paste your JSON or the provided Reza example:
```json
{
    "LicenseValidator": "Started",
    "LicenseType": "CopilotUnlimited",
    "Tag": "fluxv3:invokingfunction",
    "ModelName": "prod-gpt-5-reasoning"
}
```

## üèóÔ∏è Architecture

```
‚îú‚îÄ‚îÄ server.js           # Express server with optimization logic
‚îú‚îÄ‚îÄ index.html          # Frontend UI with tabs and optimization cards
‚îú‚îÄ‚îÄ package.json        # Dependencies (express, js-yaml, xml2js, tiktoken)
‚îî‚îÄ‚îÄ README.md          # This file
```

### Key Dependencies
- **tiktoken** - OpenAI's official tokenizer for accurate GPT-4/4.1/5.0 token counts
- **js-yaml** - YAML parsing and serialization
- **xml2js** - XML to JSON conversion
- **express** - Web server

## üìà When to Use Each Level

| Scenario | Recommended Level | Why |
|----------|------------------|-----|
| Backend JSON ‚Üí GPT-4 | **Level 2 (YAML)** | Best balance of savings + safety |
| Complex reasoning tasks | **Level 3 (Comments)** | Accuracy > token cost |
| Database storage | **Level 4 (Short Keys)** | Maximum compression |
| API contracts | **Level 1 or none** | Preserve structure |
| Synthesis layers | **Level 1** | Safe, minimal changes |

## üõ†Ô∏è For Microsoft Engineers

### Current Backend Optimization
You mentioned removing whitespace from JSON. That's good, but **Level 2 (YAML)** gives you:
- **8-10% additional savings** (on top of whitespace removal)
- **Better LLM performance** (BPE token efficiency)
- **Still readable** (unlike minified JSON)

### Quick Win Strategy
1. Start with **Level 2 (YAML)** on non-critical endpoints
2. Measure token reduction on your actual data
3. Present savings to stakeholders with this tool
4. Gradually roll out to more services

### Warning for Your Team
**DO NOT use Level 4 (Short Keys) for LLM input without key mapping.** The LLM won't understand `lv` means "LicenseValidator".

## üìù License

MIT

## üôè Acknowledgments

- OpenAI for tiktoken and GPT research
- Elya Livshitz for YAML vs JSON analysis
- Wei et al. for Chain-of-Thought prompting research
